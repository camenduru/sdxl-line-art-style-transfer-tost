{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "%cd /content/ComfyUI\n",
    "\n",
    "import os, shutil, json, requests, random, time\n",
    "from urllib.parse import urlsplit\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "from nodes import NODE_CLASS_MAPPINGS, load_custom_node\n",
    "from comfy_extras import  nodes_flux, nodes_differential_diffusion, nodes_model_advanced, nodes_custom_sampler\n",
    "\n",
    "load_custom_node(\"/content/ComfyUI/custom_nodes/comfyui-art-venture\")\n",
    "load_custom_node(\"/content/ComfyUI/custom_nodes/ComfyUI_LayerStyle\")\n",
    "load_custom_node(\"/content/ComfyUI/custom_nodes/ComfyUI_essentials\")\n",
    "load_custom_node(\"/content/ComfyUI/custom_nodes/ComfyUI-Advanced-ControlNet\")\n",
    "load_custom_node(\"/content/ComfyUI/custom_nodes/ComfyUI_SLK_joy_caption_two\")\n",
    "\n",
    "CheckpointLoaderSimple = NODE_CLASS_MAPPINGS[\"CheckpointLoaderSimple\"]()\n",
    "LoraLoader = NODE_CLASS_MAPPINGS[\"LoraLoader\"]()\n",
    "ACN_ControlNet = NODE_CLASS_MAPPINGS[\"ACN_ControlNet++LoaderSingle\"]()\n",
    "LoadBiRefNetModel = NODE_CLASS_MAPPINGS[\"LayerMask: LoadBiRefNetModel\"]()\n",
    "\n",
    "LoadImage = NODE_CLASS_MAPPINGS[\"LoadImage\"]()\n",
    "ImageBatch = NODE_CLASS_MAPPINGS[\"ImageBatch\"]()\n",
    "AV_IPAdapter = NODE_CLASS_MAPPINGS[\"AV_IPAdapter\"]()\n",
    "\n",
    "ImageScaleToMegapixels = NODE_CLASS_MAPPINGS[\"ImageScaleToMegapixels\"]()\n",
    "BiRefNetUltraV2 = NODE_CLASS_MAPPINGS[\"LayerMask: BiRefNetUltraV2\"]()\n",
    "ImageRemoveAlpha = NODE_CLASS_MAPPINGS[\"LayerUtility: ImageRemoveAlpha\"]()\n",
    "ImageDesaturate = NODE_CLASS_MAPPINGS[\"ImageDesaturate+\"]()\n",
    "AV_ControlNetPreprocessor = NODE_CLASS_MAPPINGS[\"AV_ControlNetPreprocessor\"]()\n",
    "ControlNetApplyAdvanced = NODE_CLASS_MAPPINGS[\"ControlNetApplyAdvanced\"]()\n",
    "CLIPTextEncode = NODE_CLASS_MAPPINGS[\"CLIPTextEncode\"]()\n",
    "Joy_caption_two_load = NODE_CLASS_MAPPINGS[\"Joy_caption_two_load\"]()\n",
    "Joy_caption_two = NODE_CLASS_MAPPINGS[\"Joy_caption_two\"]()\n",
    "EmptyLatentImage = NODE_CLASS_MAPPINGS[\"EmptyLatentImage\"]()\n",
    "GetImageSize = NODE_CLASS_MAPPINGS[\"GetImageSize+\"]()\n",
    "KSampler = NODE_CLASS_MAPPINGS[\"KSampler\"]()\n",
    "VAEDecode = NODE_CLASS_MAPPINGS[\"VAEDecode\"]()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    unet, clip, vae = CheckpointLoaderSimple.load_checkpoint(\"sdxl/leosamsHelloworldXL_helloworldXL70.safetensors\")\n",
    "    lora_unet, lora_clip = LoraLoader.load_lora(unet, clip, \"sdxl/araminta_k_midsommar_cartoon.safetensors\", 0.80, 1.0)\n",
    "    control_net = ACN_ControlNet.load_controlnet_plusplus(\"sdxl/controlnet-union-sdxl-1.0-promax.safetensors\", \"canny/lineart/mlsd\")[0]\n",
    "    birefnet_model = LoadBiRefNetModel.load_birefnet_model(\"BiRefNet-general-epoch_244.pth\")[0]\n",
    "    joy_two_pipeline = Joy_caption_two_load.generate(\"Llama-3.1-8B-Lexi-Uncensored-V2\")[0]\n",
    "\n",
    "def download_file(url, save_dir, file_name):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    file_suffix = os.path.splitext(urlsplit(url).path)[1]\n",
    "    file_name_with_suffix = file_name + file_suffix\n",
    "    file_path = os.path.join(save_dir, file_name_with_suffix)\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    with open(file_path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    return file_path\n",
    "\n",
    "@torch.inference_mode()\n",
    "def generate(input):\n",
    "    values = input[\"input\"]\n",
    "\n",
    "    input_image = values['input_image']\n",
    "    input_image = download_file(url=input_image, save_dir='/content/ComfyUI/input', file_name='input_image')\n",
    "    style_imag1 = values['style_imag1']\n",
    "    style_imag1 = download_file(url=style_imag1, save_dir='/content/ComfyUI/input', file_name='style_imag1')\n",
    "    style_imag2 = values['style_imag2']\n",
    "    style_imag2 = download_file(url=style_imag2, save_dir='/content/ComfyUI/input', file_name='style_imag2')\n",
    "    style_imag3 = values['style_imag3']\n",
    "    style_imag3 = download_file(url=style_imag3, save_dir='/content/ComfyUI/input', file_name='style_imag3')\n",
    "    style_imag4 = values['style_imag4']\n",
    "    style_imag4 = download_file(url=style_imag4, save_dir='/content/ComfyUI/input', file_name='style_imag4')\n",
    "    positive_prompt = values['positive_prompt']\n",
    "    negative_prompt = values['negative_prompt']\n",
    "    seed = values['seed']\n",
    "    steps = values['steps']\n",
    "    cfg = values['cfg']\n",
    "    sampler_name = values['sampler_name']\n",
    "    scheduler = values['scheduler']\n",
    "    width = values['width']\n",
    "    height = values['height']\n",
    "    enable_image_caption = values['enable_image_caption']\n",
    "    if seed == 0:\n",
    "        random.seed(int(time.time()))\n",
    "        seed = random.randint(0, 18446744073709551615)\n",
    "    input_image = LoadImage.load_image(input_image)[0]\n",
    "    input_image = ImageScaleToMegapixels.image_scale_down_to_total_pixels(input_image, megapixels=1.0)[0]\n",
    "    input_image, input_mask = BiRefNetUltraV2.birefnet_ultra_v2(input_image, birefnet_model, detail_method=\"VITMatte\", detail_erode=4, detail_dilate=2, black_point=0.01, white_point=0.99, process_detail=False, device=\"cuda\", max_megapixels=2.0)\n",
    "    input_image = ImageRemoveAlpha.image_remove_alpha(input_image, fill_background=True, background_color=\"#FFFFFF\", mask=input_mask)[0]\n",
    "    input_image = ImageDesaturate.execute(input_image, factor=1.0, method=\"luminance (Rec.601)\")[0]\n",
    "    if enable_image_caption:\n",
    "        caption_type = values['caption_type']\n",
    "        caption_length = values['caption_length']\n",
    "        low_vram = values['low_vram']\n",
    "        positive_prompt = Joy_caption_two.generate(joy_two_pipeline, input_image, caption_type, caption_length, low_vram)[0]\n",
    "    style_imag1 = LoadImage.load_image(style_imag1)[0]\n",
    "    style_imag2 = LoadImage.load_image(style_imag2)[0]\n",
    "    style_imag3 = LoadImage.load_image(style_imag3)[0]\n",
    "    style_imag4 = LoadImage.load_image(style_imag4)[0]\n",
    "    batch_image1 = ImageBatch.batch(style_imag1, style_imag2)[0]\n",
    "    batch_image2 = ImageBatch.batch(style_imag3, style_imag4)[0]\n",
    "    batch_image3 = ImageBatch.batch(batch_image1, batch_image2)[0]\n",
    "    ip_unet = AV_IPAdapter.apply_ip_adapter(\"ip-adapter_sdxl_vit-h.safetensors\", \"CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors\", lora_unet, batch_image3, weight=1.5, weight_type=\"style transfer\", start_at=0, end_at=1)[0]\n",
    "    canny_image = AV_ControlNetPreprocessor.detect_controlnet(input_image, preprocessor=\"canny\", sd_version=\"sdxl\", resolution=640, preprocessor_override=\"None\")[0]\n",
    "    positive = CLIPTextEncode.encode(clip, positive_prompt)[0]\n",
    "    negative = CLIPTextEncode.encode(clip, negative_prompt)[0]\n",
    "    positive, negative = ControlNetApplyAdvanced.apply_controlnet(positive, negative, control_net, canny_image, strength=0.65, start_percent=0.0, end_percent=0.91, vae=vae)\n",
    "    latent_image = EmptyLatentImage.generate(width, height, batch_size=1)[0]\n",
    "    samples = KSampler.sample(ip_unet, seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, denoise=1.0)[0]\n",
    "    decoded = VAEDecode.decode(vae, samples)[0].detach()\n",
    "    Image.fromarray(np.array(decoded*255, dtype=np.uint8)[0]).save(f\"/content/sdxl-{seed}-tost.png\")\n",
    "\n",
    "    result = f\"/content/sdxl-{seed}-tost.png\"\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = { \n",
    "        \"input\": {\n",
    "        \"input_image\": \"https://files.catbox.moe/kxihm6.jpg\",\n",
    "        \"style_imag1\": \"https://files.catbox.moe/bdzw7s.png\",\n",
    "        \"style_imag2\": \"https://files.catbox.moe/59u8q5.png\",\n",
    "        \"style_imag3\": \"https://files.catbox.moe/ctpfk2.png\",\n",
    "        \"style_imag4\": \"https://files.catbox.moe/gjy7lc.png\",\n",
    "        \"enable_image_caption\": True,\n",
    "        \"caption_type\": \"Booru tag list\",\n",
    "        \"caption_length\": \"short\",\n",
    "        \"low_vram\": True,\n",
    "        \"positive_prompt\": \"solo, simple_background, white_background, monochrome, no_humans, robot, mecha, science_fiction\",\n",
    "        \"negative_prompt\": \"nsfw, naked, rope\",\n",
    "        \"seed\": 0,\n",
    "        \"steps\": 20,\n",
    "        \"cfg\": 5.3,\n",
    "        \"sampler_name\": \"dpmpp_sde\",\n",
    "        \"scheduler\": \"karras\",\n",
    "        \"width\": 1024,\n",
    "        \"height\": 1024\n",
    "    }\n",
    "}\n",
    "image = generate(input)\n",
    "Image.open(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ComfyUI-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
